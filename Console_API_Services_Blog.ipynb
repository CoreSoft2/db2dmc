{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talking to Db2 with open RESTful APIs and micro-services\n",
    "The new Db2 Data Management Console is a free browser based user interface included with Db2 for Linux, UNIX and Windows. Its more than a graphical user interface to monitor, manage and optimize Db2. It is a set of open RESTful APIs and micro-services for DB2. \n",
    "\n",
    "Everything in the User Interface is available through an open and fully documented RESTful Services API. You can also embed elements of the user interface into your own webpages, or Jupyter notebooks.\n",
    "\n",
    "This Jupyter Notebook contains examples of how to use the open RESTful APIs and the composable user interfaces that are available in the Db2 Data Management Console. \n",
    "\n",
    "You can find out more about the Db2 Console at www.ibm.biz/Db2Console. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to find this sample online\n",
    "You can find a copy of this notebook at https://github.com/Db2-DTE-POC/db2dmc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we will import a few helper classes\n",
    "We need to pull in a few standard Python libraries so that we can work with REST, JSON and communicate with the Db2 Console APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class libraries \n",
    "import requests\n",
    "import ssl\n",
    "import json\n",
    "from pprint import pprint\n",
    "from requests import Response\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Db2 Class\n",
    "Next we will create a Db2 helper class that will encapsulate the Rest API calls that we can use to access the Db2 Console service.\n",
    "\n",
    "To access the service, we need to first authenticate with the service and create a reusable token that we can use for each call to the service. This ensures that we don't have to provide a userID and password each time we run a command. The token makes sure this is secure. \n",
    "\n",
    "Each request is constructed of several parts. First, the URL and the API identify how to connect to the service. Second the REST service request that identifies the request and the options. For example '/metrics/applications/connections/current/list'. Some complex requests also include a JSON payload. For example running SQL includes a JSON object that identifies the script, statement delimiters, the maximum number of rows in the results set as well as what do if a statement fails.\n",
    "\n",
    "The full set of APIs are documents as part of the Db2 Data Management Console user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Db2 Class library\n",
    "# Used to construct and reuse an Autentication Key\n",
    "# Used to construct RESTAPI URLs and JSON payloads\n",
    "class Db2():\n",
    "    \n",
    "    def __init__(self, url, verify = False, proxies=None, ):\n",
    "        self.url = url\n",
    "        self.proxies = proxies\n",
    "        self.verify = verify\n",
    "\n",
    "    def authenticate(self, userid, password, profile=\"\"):\n",
    "        credentials = {'userid':userid, 'password':password}\n",
    "        r = requests.post(self.url+'/auth/tokens', verify=self.verify, json=credentials, proxies=self.proxies)\n",
    "        if (r.status_code == 200):\n",
    "            bearerToken = r.json()['token']\n",
    "            if profile == \"\":\n",
    "                self.headers = {'Authorization': 'Bearer'+ ' '+bearerToken}\n",
    "            else:\n",
    "                self.headers = {'Authorization': 'Bearer'+ ' '+bearerToken, 'X-DB-Profile': profile}\n",
    "        else:\n",
    "            print ('Unable to authenticate, no bearer token obtained')\n",
    "    \n",
    "    def getRequest(self, api, json=None):\n",
    "        return requests.get(self.url+api, verify = self.verify, headers=self.headers, proxies = self.proxies, json=json)\n",
    "\n",
    "    def postRequest(self, api, json=None):\n",
    "        return requests.post(self.url+api, verify = self.verify, headers=self.headers, proxies = self.proxies, json=json) \n",
    "        \n",
    "    def getStatusCode(self, response):\n",
    "        return (response.status_code)\n",
    "\n",
    "    def getJSON(self, response):\n",
    "        return (response.json())     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing a Connection to the Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Connections\n",
    "To connect to the Db2 Data Management Console service you need to provide the URL, the service name (v4) and profile the console user name and password as well as the name of the connection profile used in the console to connect to the database you want to work with. For this lab we are assuming that the following values are used for the connection:\n",
    "* Userid: db2inst1\n",
    "* Password: db2inst1\n",
    "* Connection: sample\n",
    "\n",
    "**Note:** If the Db2 Data Management Console has not completed initialization, the connection below will fail. Wait for a few moments and then try it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Db2 Data Management Console service\n",
    "Console  = 'http://localhost:11080'\n",
    "profile  = 'SAMPLE'\n",
    "user     = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "# Set up the required connection\n",
    "profileURL = \"?profile=\"+profile\n",
    "databaseAPI = Db2(Console+'/dbapi/v4')\n",
    "databaseAPI.authenticate(user, password, profile)\n",
    "database = Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm the connection\n",
    "To confirm that your connection is working you can check your console connection to get the details of the specific database connection you are working with. Since your console user id and password may be limited as to which databases they can access you need to provide the connection profile name to drill down on any detailed information for the database.\n",
    "Take a look at the JSON that is returned by the call in the cell below. You can see the name of the connection profile, the database name, the database instance the database belongs to, the version, release and edition of Db2 as well as the operating system it is running on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Monitoring Profile\n",
    "r = databaseAPI.getRequest('/dbprofiles/'+profile)\n",
    "json = databaseAPI.getJSON(r)\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check the status of the moitoring service. This call take a bit longer since it is running a quick diagnostic check on the Db2 Data Management Console monitoring service. You should see that the both the database and authentication services are online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Monitor Status\n",
    "r = databaseAPI.getRequest('/monitor') \n",
    "json = databaseAPI.getJSON(r)\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Available Schemas in the Database\n",
    "You can call the Db2 Data Management Console micro service to provide an active console component that you can include in an IFrame directly into your notebook. The first time you access this you will have to log in just like any other time you use the console for the first time. If you want to see all the schemas, including the catalog schemas, select the \"Show system schemas\" toggle at the right side of the panel. \n",
    "* Userid: db2inst1\n",
    "* Password: db2inst1\n",
    "\n",
    "**Note:** You may need to logon to the console for the frame to be displayed.\n",
    "\n",
    "When the interface appears:\n",
    "\n",
    "Click on **Show system schemas** at the right side of the screen. This displays all the schemas in the Db2 catalog as well as user schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(database+'/console/?mode=compact#explore/schema'+profileURL, width=1400, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the same list through the REST service call. In this example the service call text was defined in the Db2 class at the start of the notebook. By default it includes both user and catalog schemas. \n",
    "\n",
    "If the call is successful it will return a 200 status code. The API call returns a JSON structure that we turn into a Pandas DataFrame using the normalize function. You can then list the columns of data available in the Data Frame and display the first 10 rows in the data frame. \n",
    "\n",
    "Many of the examples below list the columns available in the dataframe to make it easier for you to adapt the examples to your own needs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next example we need to import the Pandas libraries to use DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = databaseAPI.getRequest('/schemas')\n",
    "\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    df = pd.DataFrame(json_normalize(json['resources']))\n",
    "    print(', '.join(list(df)))\n",
    "    display(df[['name']].head(10))\n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Search\n",
    "You can search the objects in your database through the search objects API. This API requires an JSON payload to define the search criteria which can be complex. In this example we are looking for Views with \"table\" in their name. It will search through both user and catalog views. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for tables across all schemas that match simple search critera \n",
    "# Display the first 100\n",
    "# Switch between searching tables or views\n",
    "obj_type = 'view'\n",
    "# obj_type = 'table'\n",
    "search_text = 'TABLE'\n",
    "rows_return=10\n",
    "show_systems='true'\n",
    "is_ascend='true'\n",
    "\n",
    "json = {\"search_name\":search_text,\"rows_return\":rows_return,\"show_systems\":show_systems,\"obj_type\":obj_type,\"filters_match\":\"ALL\",\"filters\":[]}       \n",
    "\n",
    "r = databaseAPI.postRequest('/admin/'+str(obj_type)+'s',json);\n",
    "\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    df = pd.DataFrame(json_normalize(json))\n",
    "    print('Columns:')\n",
    "    print(', '.join(list(df)))\n",
    "    display(df[[obj_type+'_name']].head(100))\n",
    "else:\n",
    "    print(\"RC: \"+str(databaseAPI.getStatusCode(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example returns all the tables in a single schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the tables in the SYSIBM schema and display the first 10\n",
    "schema = 'SYSIBM'\n",
    "r = databaseAPI.getRequest('/schemas/'+str(schema)+'/tables');\n",
    "\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    df = pd.DataFrame(json_normalize(json['resources']))\n",
    "    print(', '.join(list(df)))\n",
    "    display(df[['schema','name']].head(10))\n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Key Performance Metrics\n",
    "You can access key high level performance metrics by directly including the monitoring summary page in an IFrame or calling the available API. To see the time series history of the number of rows read in your system over the last day, run the statement below. Then scroll to the right side and find the Database Throughput Widget. Then select Rows Read and Last 24 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(database+'/console/?mode=compact#monitor/summary'+profileURL, width=1400, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the same data directly through an API you can use the getRowsRead function as defined in the Db2 class at the start of the notebook. To extract the timeseries data from the JSON returned from the API call you need to access the 'timeseries' part of the full JSON data set. \n",
    "\n",
    "The example below retrieves the last hour of data, converts it from JSON to a DataFrame and then displays and graphs the data. Notice that the timeseries data is returned as EPOC data. That is the number of seconds since January 1st 1970. The epochtotimeseries routine we created earlier in the lab converts that to human readable timeseries data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Data\n",
    "Since Db2 stores time series data as epoch time we need to do some simple calculations to determine current time as well as the duration of a week or a day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the number of rows read over the last day\n",
    "import time\n",
    "endTime = int(time.time())*1000\n",
    "startTime = endTime-(60*60*1000)\n",
    "\n",
    "# Return the rows read rate over the last hour\n",
    "r = databaseAPI.getRequest('/metrics/rows_read?start='+str(startTime)+'&end='+str(endTime));\n",
    "\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    if json['count'] > 0:\n",
    "        df = pd.DataFrame(json_normalize(json['timeseries'])) #extract just the timeseries data\n",
    "        print('Available Columns')\n",
    "        print(', '.join(list(df)))\n",
    "    else: \n",
    "        print('No data returned')\n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPOC Time Conversion\n",
    "Db2 returns time series data in Unix epoch time. The first function below converts between epoch and human readable time series format. The second function simply converts values from KB to GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data frame set calculation functions\n",
    "def epochtotimeseries(epoch):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(epoch/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from EPOCH to timeseries data\n",
    "# Display the last 20 datapoints\n",
    "df['timestamp'] = df['timestamp'].apply(epochtotimeseries)\n",
    "display(df[['timestamp','rows_read_per_min']].tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "df.plot.line(x='timestamp',y='rows_read_per_min') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Usage\n",
    "You can access the storage report page directly by calling it into an IFrame or you can access the data from an API. In the report below you can select the timeframe for storage usage, group by table or schema, select the object you want to analyze and then select View Details from the Actions column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(database+'/console/?mode=compact#monitor/storage'+profileURL, width=1400, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also list storage by schema. The following example retrieves the current level of storage usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List storage used by schema\n",
    "# Display the top ten schemas\n",
    "r = databaseAPI.getRequest('/metrics/storage/schemas?end=0&include_sys=true&limit=1000&offset=0&start=0') \n",
    "\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)        \n",
    "    if json['count'] > 0: \n",
    "        df = pd.DataFrame(json_normalize(json['resources']))\n",
    "        print(', '.join(list(df)))\n",
    "        df['space_mb'] = df['data_physical_size_kb'].apply(lambda x: x / 1024)\n",
    "        df = df.sort_values(by='data_physical_size_kb', ascending=False)    \n",
    "        display(df[['tabschema','space_mb']].head(10))\n",
    "    else: \n",
    "        print('No data returned') \n",
    "else:\n",
    "    print(\"RC: \"+str(databaseAPI.getStatusCode(r)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "You can find a copy of this notebook at https://github.com/Db2-DTE-POC/db2dmc. This github library includes several other notebooks that that cover more advanced examples of how to use Db2 and Jupyter together through open APIs. \n",
    "\n",
    "You can also access a free hands-on interactive lab that uses all of the notebooks at: https://www.ibm.com/demos/collection/IBM-Db2-Data-Management-Console/. After you sign up for the lab you will get access to a live cloud based system running Db2, the Db2 Console as well as extensive Jupyter Notebooks and Python to help you learn more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits: IBM 2019, Peter Kohlmann [kohlmann@ca.ibm.com]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
