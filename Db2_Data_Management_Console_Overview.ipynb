{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Db2 Data Management Console Overview\n",
    "\n",
    "This Jupyter Notebook contains examples of how to use the Open APIs and composable interface that is available in the Db2 Data Management Console. Everything in the User Interface is also available through an open and fully documented RESTful Services API. You can find the full documentation in the Help included with the Db2 Data Management Console.\n",
    "\n",
    "You can also embed elements of the full user interface into an IFrame by constructing the appropriate URL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we will import a few helper classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class libraries \n",
    "import requests\n",
    "import ssl\n",
    "import json\n",
    "from pprint import pprint\n",
    "from requests import Response\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display, HTML\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Db2 Class\n",
    "Next we will create a Db2 helper class that will encapsulate the Rest API calls that we can use to directly access the Db2 Data Management Console service without having to use the user interface. \n",
    "\n",
    "To access the service we need to first authenticate with the service and create a reusable token that we can use for each call to the service. This ensures that we don't have to provide a userID and password each time we run a command. The token makes sure this is secure. \n",
    "\n",
    "Each request is constructed of several parts. First, the URL and the API identify how to connect to the service. Second the REST service request that identifies the request and the options. For example '/metrics/applications/connections/current/list'. And finally some complex requests also include a JSON payload. For example running SQL includes a JSON object that identifies the script, statement delimiters, the maximum number of rows in the results set as well as what do if a statement fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Db2 Class library\n",
    "# Used to construct and reuse an Autentication Key\n",
    "# Used to construct RESTAPI URLs and JSON payloads\n",
    "class Db2():\n",
    "    \n",
    "    def __init__(self, url, verify = False, proxies=None, ):\n",
    "        self.url = url\n",
    "        self.proxies = proxies\n",
    "        self.verify = verify\n",
    "\n",
    "    def authenticate(self, userid, password, profile=\"\"):\n",
    "        credentials = {'userid':userid, 'password':password}\n",
    "        r = requests.post(self.url+'/auth/tokens', verify=self.verify, json=credentials, proxies=self.proxies)\n",
    "        if (r.status_code == 200):\n",
    "            bearerToken = r.json()['token']\n",
    "            if profile == \"\":\n",
    "                self.headers = {'Authorization': 'Bearer'+ ' '+bearerToken}\n",
    "            else:\n",
    "                self.headers = {'Authorization': 'Bearer'+ ' '+bearerToken, 'X-DB-Profile': profile}\n",
    "        else:\n",
    "            print ('Unable to authenticate, no bearer token obtained')\n",
    "        \n",
    "    def printResponse(self, r, code):\n",
    "        if (r.status_code == code):\n",
    "            pprint(r.json())\n",
    "        else:\n",
    "            print (r.status_code)\n",
    "            print (r.content)\n",
    "    \n",
    "    def getRequest(self, api, json=None):\n",
    "        return requests.get(self.url+api, verify = self.verify, headers=self.headers, proxies = self.proxies, json=json)\n",
    "\n",
    "    def postRequest(self, api, json=None):\n",
    "        return requests.post(self.url+api, verify = self.verify, headers=self.headers, proxies = self.proxies, json=json) \n",
    "        \n",
    "    def getStatusCode(self, response):\n",
    "        return (response.status_code)\n",
    "\n",
    "    def getJSON(self, response):\n",
    "        return (response.json())\n",
    "    \n",
    "    def getSchemas(self):\n",
    "        return self.getRequest('/schemas')\n",
    "    \n",
    "    def runSQL(self, script, limit=10, separator=';', stopOnError=False):\n",
    "        sqlJob = {'commands': script, 'limit':limit, 'separator':separator, 'stop_on_error':str(stopOnError)}\n",
    "        return self.postRequest('/sql_jobs',sqlJob)\n",
    "        \n",
    "    def getSQLJobResult(self, jobid):\n",
    "        return self.getRequest('/sql_jobs/'+jobid)\n",
    "    \n",
    "    def getCurrentApplicationsConnections(self, includeSystem='true'):\n",
    "        return self.getRequest('/metrics/applications/connections/current/list?&include_sys='+str(includeSystem))\n",
    "    \n",
    "    def getInflightCount(self, startTime, endTime):\n",
    "        return self.getRequest('/metrics/statements/inflight_executions/current/list?start='+str(startTime)+'&end='+str(endTime));\n",
    "       \n",
    "    def getInflightCurrentList(self, includeSystem='true'):\n",
    "        return self.getRequest('/metrics/statements/inflight_executions/current/list?'+'&include_sys='+str(includeSystem));\n",
    "    \n",
    "    def getIndividualStatementExecution(self, startTime, endTime, limit=100, includeSystem='false'):\n",
    "        return self.getRequest('/metrics/statements/evmon_activity?start='+str(startTime)+'&end='+str(endTime)+'&include_sys='+str(includeSystem)+'&offset=0&limit='+str(limit))\n",
    "\n",
    "    def getFiles(self, path):\n",
    "        return self.getRequest('/home'+path)\n",
    "    \n",
    "    def getUsers(self):\n",
    "        return self.getRequest('/users')\n",
    "    \n",
    "    def getTablesMetrics(self, startTime, endTime, includeSystem='false'):\n",
    "        return self.getRequest('/metrics/tables?start='+str(startTime)+'&end='+str(endTime)+'&include_sys='+str(includeSystem));\n",
    "\n",
    "    def getAverageResponseTime(self, startTime, endTime):\n",
    "        return self.getRequest('/metrics/average_response_time?start='+str(startTime)+'&end='+str(endTime));    \n",
    "    \n",
    "    def getUnitsOfWork(self, startTime, endTime):\n",
    "        return self.getRequest('/applications/uow?start='+str(startTime)+'&end='+str(endTime));    \n",
    "    \n",
    "    def getSchemaSize(self, startTime, endTime, tabSchema):\n",
    "        return self.getRequest('/metrics/storage/schemas/'+tabSchema+'/timeseries?start='+str(startTime)+'&end='+str(endTime));\n",
    "  \n",
    "    def getSearchViewList(self, searchtext, show_systems=\"false\"):\n",
    "        return self.getRequest('/admin/schemas/obj_type/view?search_name='+searchtext+'&show_systems='+str(show_systems)+'&rows_return=200');\n",
    "    \n",
    "    def getSearchTableList(self, searchtext):\n",
    "        return self.getRequest('/admin/schemas/obj_type/table?search_name='+searchtext+'&show_systems=true&rows_return=100');\n",
    "              \n",
    "    def getRowsRead(self, startTime, endTime):\n",
    "        return self.getRequest('/metrics/rows_read?start='+str(startTime)+'&end='+str(endTime));\n",
    "\n",
    "    def getResponseTime(self, startTime, endTime):\n",
    "        return self.getRequest('/metrics/response_time?start='+str(startTime)+'&end='+str(endTime));\n",
    "\n",
    "    def getStatementsCount(self, startTime, endTime):\n",
    "        return self.getRequest('/metrics/statements_count?start='+str(startTime)+'&end='+str(endTime));\n",
    "\n",
    "    def getPackageCacheStatement(self, startTime, endTime, show_systems='true'):\n",
    "        return self.getRequest('/metrics/statements/package_cache?start='+str(startTime)+'&end='+str(endTime)+'&show_systems='+str(show_systems))\n",
    "    \n",
    "    def postSearchObjects(self, obj_type, search_text, rows_return=100, show_systems='false', is_ascend='true'):     \n",
    "        json = {\"search_name\":search_text,\"rows_return\":rows_return,\"show_systems\":show_systems,\"obj_type\":obj_type,\"filters_match\":\"ALL\",\"filters\":[]}       \n",
    "        return self.postRequest('/admin/'+str(obj_type)+'s',json);\n",
    "                \n",
    "    def putFile(self, filename, path):\n",
    "        with open(filename, 'rb') as f:\n",
    "            r = requests.post(self.url+'/home_content/path', files={filename: f}, verify = self.verify, headers=self.headers, proxies = self.proxies)\n",
    "            \n",
    "    def getTablesInSchema(self, schema):\n",
    "        return self.getRequest('/schemas/'+str(schema)+'/tables');\n",
    "    \n",
    "    def getTableStorageBySchema(self):\n",
    "        return self.getRequest('/metrics/storage/schemas?end=0&include_sys=true&limit=1000&offset=0&start=0')\n",
    "    \n",
    "    def getCurrentPackageCacheList(self, show_systems=\"false\"):\n",
    "        return self.getRequest('/metrics/statements/package_cache/current/list?include_sys='+str(show_systems))\n",
    "    \n",
    "    def getProfile(self,profile):\n",
    "        return self.getRequest('/dbprofiles/'+profile)    \n",
    "    \n",
    "    def getMonitorStatus(self):\n",
    "        return self.getRequest('/monitor')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion Classes\n",
    "Db2 returns time series data in Unix epoch time. The first function below converts between epoch and human readable time series format. The second fucntion simply converts valules from KB to GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data frame set calculation functions\n",
    "def epochtotimeseries(epoch):\n",
    "    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(epoch/1000))\n",
    "def KBtoGB(kb):\n",
    "    return kb/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Calculations\n",
    "Since Db2 stores time series data as epoch time we need to do some simple calculations to determine current time as well as the duration of a week or a day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup time series calculation values\n",
    "import time\n",
    "from datetime import date\n",
    "endTime = int(time.time())\n",
    "endTime = endTime*1000\n",
    "startTime = endTime-(600*1000)\n",
    "oneWeek = 604800000\n",
    "oneDay = 86400000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing a Connection to the Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Connections\n",
    "To connect to the Db2 Data Management Console service you need to provide the URL, the service name (v4) and profile the console user name and password as well as the name of the connection profile used in the console to connect to the database you want to work with. For this lab we are assuming that the following values are used for the connection:\n",
    "* Userid: db2inst1\n",
    "* Password: db2inst1\n",
    "* Connection: sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Db2 Data Management Console service\n",
    "Console  = 'http://localhost:11080'\n",
    "profile  = 'SAMPLE'\n",
    "user     = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "# Set up the required connection\n",
    "profileURL = \"?profile=\"+profile\n",
    "databaseAPI = Db2(Console+'/dbapi/v4')\n",
    "databaseAPI.authenticate(user, password, profile)\n",
    "database = Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm the connection\n",
    "To confirm that your connection is working you can check the status of the moitoring service. You can also check your console connection to get the details of the specific database connection you are working with. Since your console user id and password are may be limited as to which databases they can access you need to provide the connection profile name to drill down on any detailed information for the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Monitor Status\n",
    "r = databaseAPI.getMonitorStatus()\n",
    "json = databaseAPI.getJSON(r)\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Monitoring Profile\n",
    "r = databaseAPI.getProfile(profile)\n",
    "json = databaseAPI.getJSON(r)\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Available Schemas in the Database\n",
    "You can call the Db2 Data Management Console micro service to provide an active console component that you can include in an IFrame directly into your notebook. The first time you access this you will have to log in just like any other time you use the console for the first time. If you want to see all the schemas, including the catalog schemas, select the \"Show system schemas\" toggle at the right side of the panel. \n",
    "* Userid: db2inst1\n",
    "* Password: db2inst1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(database+'/console/?mode=compact#explore/schema'+profileURL, width=1400, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the same list through the REST service call. In this example the service call text was defined in the Db2 class at the start of the notebook. By default it includes both user and catalog schemas. \n",
    "\n",
    "If the call is successful it will return a 200 status code. The API call returns a JSON structure that we turn into a DataFrame using the normalize function. You can then list the columns of data available in the Data Frame and display the first 10 rows in the data frame. \n",
    "\n",
    "Many of the examples below list the columns available in the dataframe to make it easier for you to adapt the examples to your own needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = databaseAPI.getSchemas()\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    df = pd.DataFrame(json_normalize(json['resources']))\n",
    "    print(', '.join(list(df)))\n",
    "    display(df[['name']].head(10))\n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Key Performance Metrics\n",
    "You can access key high level performance metrics by directly including the monitoring summary page in an IFrame or calling the available API. To see the time series history of the number of rows read in your system over the last day. Run the statement blow. Then scroll to the right side and find the Database Throughput Widget. Then select Rows Read and Last 24 hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(database+'/console/?mode=compact#monitor/summary'+profileURL, width=1400, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the same data directly through an API you can use the getRowsRead function as defined in the Db2 class at the start of the notebook. To extract the timeseries data from the JSON returned from the API call you need to access the 'timeseries' part of the full JSON data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the number of rows read over the last day\n",
    "# List the last 10 data points\n",
    "# Graph the history\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lastDay = endTime - oneDay\n",
    "r = databaseAPI.getRowsRead(lastDay, endTime)\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    if json['count'] > 0:\n",
    "        df = pd.DataFrame(json_normalize(json['timeseries'])) #extract just the timeseries data\n",
    "        print('Available Columns')\n",
    "        print(', '.join(list(df)))\n",
    "        df['timestamp'] = df['timestamp'].apply(epochtotimeseries)\n",
    "        display(df[['timestamp','rows_read_per_min']].tail(20))\n",
    "        df.plot.line(x='timestamp',y='rows_read_per_min') \n",
    "        plt.show()\n",
    "    else: \n",
    "        print('No data returned')\n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Usage\n",
    "You can access the storage report page directly by calling it into an IFrame or you can access the data from an API. In the report below you can select the timeframe for storage usage, group by table or schema, select the object you want to analyze and then select View Details from the Actions column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(database+'/console/?mode=compact#monitor/storage'+profileURL, width=1400, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also list storage by schema. The following example retrieves the current level of storage usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List storage used by schema\n",
    "# Display the top ten schemas\n",
    "r = databaseAPI.getTableStorageBySchema()\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)        \n",
    "    if json['count'] > 0: \n",
    "        df = pd.DataFrame(json_normalize(json['resources']))\n",
    "        print(', '.join(list(df)))\n",
    "        df['space_mb'] = df['data_physical_size_kb'].apply(lambda x: x / 1024)\n",
    "        df = df.sort_values(by='data_physical_size_kb', ascending=False)    \n",
    "        display(df[['tabschema','space_mb']].head(10))\n",
    "    else: \n",
    "        print('No data returned') \n",
    "else:\n",
    "    print(\"RC: \"+str(databaseAPI.getStatusCode(r)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Management\n",
    "You can explore the objects in your database through the search objects API. This API requires an JSON payload to define the search criteria which can be complex. In this example we are looking for Views with \"table\" in their name. It will search through both user and catalog views. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for tables across all schemas that match simple search critera \n",
    "# Display the first 100\n",
    "# Switch between searching tables or views\n",
    "object = 'view'\n",
    "#object = 'table'\n",
    "r = databaseAPI.postSearchObjects(object,\"TABLE\",10,'true','false')\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    df = pd.DataFrame(json_normalize(json))\n",
    "    print('Columns:')\n",
    "    print(', '.join(list(df)))\n",
    "    display(df[[object+'_name']].head(100))\n",
    "else:\n",
    "    print(\"RC: \"+str(databaseAPI.getStatusCode(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example returns all the tables in a single schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the tables in the SYSIBM schema and display the first 10\n",
    "schema = 'SYSIBM'\n",
    "r = databaseAPI.getTablesInSchema(schema)\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    df = pd.DataFrame(json_normalize(json['resources']))\n",
    "    print(', '.join(list(df)))\n",
    "    display(df[['schema','name']].head(10))\n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Your History Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are connected to the database you use to collect historical data you can determine how much storage is being used with the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Db2 Data Management Console service\n",
    "Console  = 'http://localhost:11080'\n",
    "profile  = 'HISTORY'\n",
    "user     = 'DB2INST1'\n",
    "password = 'db2inst1'\n",
    "\n",
    "# Set up the required connection\n",
    "profileURL = \"?profile=\"+profile\n",
    "databaseAPI = Db2(Console+'/dbapi/v4')\n",
    "databaseAPI.authenticate(user, password, profile)\n",
    "database = Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the storage size for the Historical Data Repostory stored in IBMCONSOLE schema. If this doesn't run against the repository database you will get a zero result set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the last 10 data points\n",
    "# Graph the history of the storage usage\n",
    "tabSchema = 'IBMCONSOLE'\n",
    "OneWeekStartTime = endTime - oneWeek\n",
    "r = databaseAPI.getSchemaSize(0, endTime, tabSchema)\n",
    "if (databaseAPI.getStatusCode(r)==200):\n",
    "    json = databaseAPI.getJSON(r)\n",
    "    if json['count'] > 0: \n",
    "        df = pd.DataFrame(json_normalize(json['timeseries']))\n",
    "        print('Columns')\n",
    "        print(', '.join(list(df)))\n",
    "        df['total_physical_size_gb'] = df['total_physical_size_kb'].apply(KBtoGB)\n",
    "        df['timestamp'] = df['timestamp'].apply(epochtotimeseries)\n",
    "        display(df[['timestamp','total_physical_size_gb']].tail(10))\n",
    "        df.plot(x='timestamp',y='total_physical_size_gb')\n",
    "    else: \n",
    "        print('No data returned') \n",
    "else:\n",
    "    print(databaseAPI.getStatusCode(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits: IBM 2019, Peter Kohlmann [kohlmann@ca.ibm.com]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
